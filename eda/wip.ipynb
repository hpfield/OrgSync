{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory:  c:\\Users\\dec2g\\GitHub\\OrgSync\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import json\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import collections\n",
    "from typing import Dict, List, Set\n",
    "\n",
    "from data_matching import *\n",
    "\n",
    "def move_working_dir_to_repo_root(repo_name=\"orgsync\"):\n",
    "    \"\"\"\n",
    "    Move the current working directory to the root of the repository.\n",
    "    \"\"\"\n",
    "    current_dir = os.getcwd()\n",
    "    while os.path.basename(current_dir).lower() != repo_name:\n",
    "        current_dir = os.path.dirname(current_dir)\n",
    "    os.chdir(current_dir)\n",
    "    print(\"Current working directory: \", os.getcwd())\n",
    "\n",
    "move_working_dir_to_repo_root(repo_name=\"orgsync\")\n",
    "\n",
    "# Define the base path and the file paths \n",
    "\n",
    "base_path = os.path.join(\"data\", \"raw\")\n",
    "gtr_base = os.path.join(base_path, \"all_scraped\", \"gtr\", \"scraped\")\n",
    "gtr_persons_json = os.path.join(gtr_base, \"2024_07\", \"persons.json\")\n",
    "gtr_projects_json = os.path.join(gtr_base, \"2024_07\", \"projects.json\")\n",
    "gtr_organisations_json = os.path.join(gtr_base, \"2024_07\", \"organisations.json\")\n",
    "\n",
    "# gtr_persons_json = os.path.join(\"data\", \"raw\", \"example_data\", \"persons.json\")\n",
    "# gtr_projects_json = os.path.join(\"data\", \"raw\", \"example_data\", \"projects.json\")\n",
    "# gtr_organisations_json = os.path.join(\"data\", \"raw\", \"example_data\", \"organisations.json\")\n",
    "# with open(gtr_projects_json, \"r\") as f:\n",
    "#     projects_data = json.load(f)\n",
    "\n",
    "def get_data(file_path: str) -> Dict:\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_id_from_href(href: str) -> str:\n",
    "    return href.split('/')[-1]\n",
    "\n",
    "def extract_domain_from_href(href: str) -> str:\n",
    "    return href.split('/')[-2]\n",
    "\n",
    "def get_hrefs_as_dict_of_lists(entry, rels):\n",
    "    link_dicts = entry[\"links\"][\"link\"]\n",
    "    # populate with {rel: [list]}\n",
    "    rel_lists = {rel: [] for rel in rels}\n",
    "    for link_item in link_dicts:        \n",
    "        if link_item[\"rel\"] in rels:\n",
    "            rel_lists[link_item[\"rel\"]].append(link_item[\"href\"])\n",
    "            rel_lists[link_item[\"rel\"]+\"_ids\"] = [extract_id_from_href(href) for href in rel_lists[link_item[\"rel\"]]]\n",
    "    return rel_lists\n",
    "\n",
    "def transform_data(data: List[Dict], keys: Dict, rels: List)  -> List[Dict]:\n",
    "    transformed = []\n",
    "    for entry in data:\n",
    "        data_transformed = {}\n",
    "        for key, value in keys.items():\n",
    "            data_transformed[key] = entry[value]\n",
    "            href_dict = get_hrefs_as_dict_of_lists(entry, rels)\n",
    "            # merge the transformed person with the hrefs\n",
    "            data_transformed = {**data_transformed, **href_dict}\n",
    "        transformed.append(data_transformed)\n",
    "    return transformed\n",
    "\n",
    "### Quick check\n",
    "# get first element of the persons.json\n",
    "# persons = get_data(gtr_persons_json)\n",
    "# # person = persons[10] # example of sparse person\n",
    "# entry = persons[0] # example of person fully populated\n",
    "# # pprint(persons)\n",
    "# hrefs = get_hrefs_as_dict_of_lists(entry, person_rels)\n",
    "# pprint(hrefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# personan keys are used to extract the data from the json file that are not nested\n",
    "# difference in key - value is just prefernece, for example if we want to specify that an id \n",
    "# is for a person so we can join with other datasets that also include an ID field but for orgs \n",
    "# or projects\n",
    "person_keys = {\n",
    "    \"person_id\": \"id\",\n",
    "    \"firstName\": \"firstName\",\n",
    "    \"surname\": \"surname\",\n",
    "    \"otherNames\": \"otherNames\",\n",
    "    \"email\": \"email\",\n",
    "    \"orcidId\": \"orcidId\",\n",
    "    \"created\": \"created\",\n",
    "}\n",
    "\n",
    "# rels is a list of the `rel` fields in the nested list of dictionaries in the json file\n",
    "# Each returns an href to another json file that contins information about projects, organisations etc. \n",
    "person_rels = [\"EMPLOYED\", \"PI_PER\", \"COI_PER\"]\n",
    "\n",
    "persons = get_data(gtr_persons_json)\n",
    "persons_transformed = transform_data(persons, person_keys, person_rels)\n",
    "# pprint(persons_transformed)\n",
    "# create folder if doesn't exist\n",
    "os.makedirs(\"data/transformed\", exist_ok=True)\n",
    "# save persons transformed and organisations transformed to csv\n",
    "persons_df = pd.DataFrame(persons_transformed)\n",
    "persons_df.to_csv(\"data/transformed/persons.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "organisation_keys = {\n",
    "    \"name\": \"name\",\n",
    "    \"organisation_id\": \"id\",\n",
    "    \"website\": \"website\",\n",
    "    \"created\": \"created\"\n",
    "    # ignore postcode/ location for now.\n",
    "    # ad \"created\" back in at some point could be helpful, same with projects and persons.\n",
    "}\n",
    "\n",
    "organisation_rels = [\"EMPLOYEE\", \"PROJECT\"]\n",
    "\n",
    "organisations = get_data(gtr_organisations_json)\n",
    "organisations_transformed = transform_data(organisations, organisation_keys, organisation_rels)\n",
    "# pprint(organisations_transformed)\n",
    "\n",
    "\n",
    "organisations_df = pd.DataFrame(organisations_transformed)\n",
    "organisations_df.to_csv(\"data/transformed/organisations.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joining Datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "1. Do we really want to be renaming fields like id -> organisation_id, or handle that at the point of joining?\n",
    "2. We should really save the data iteratively, and allow it to run from the last processed entry. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dan-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
