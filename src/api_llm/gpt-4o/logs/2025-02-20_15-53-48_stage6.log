2025-02-20 15:53:49,317 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-20 15:53:50,308 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-20 15:53:50,920 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-20 15:53:52,088 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-20 15:53:53,103 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-6' coro=<process_group_with_llm() done, defined at /home/ubuntu/OrgSync/src/api_llm/gpt-4o/stages/stage6.py:96> exception=KeyboardInterrupt()>
Traceback (most recent call last):
  File "/home/ubuntu/OrgSync/src/api_llm/gpt-4o/main.py", line 333, in <module>
    main()
  File "/home/ubuntu/OrgSync/src/api_llm/gpt-4o/main.py", line 230, in main
    refined_groups = asyncio.run(stage6_process_groups_with_llm(grouped_names, method_sub_db))
  File "/home/ubuntu/miniforge3/envs/orgsync/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/home/ubuntu/miniforge3/envs/orgsync/lib/python3.10/asyncio/base_events.py", line 636, in run_until_complete
    self.run_forever()
  File "/home/ubuntu/miniforge3/envs/orgsync/lib/python3.10/asyncio/base_events.py", line 603, in run_forever
    self._run_once()
  File "/home/ubuntu/miniforge3/envs/orgsync/lib/python3.10/asyncio/base_events.py", line 1909, in _run_once
    handle._run()
  File "/home/ubuntu/miniforge3/envs/orgsync/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/home/ubuntu/OrgSync/src/api_llm/gpt-4o/stages/stage6.py", line 154, in process_group_with_llm
    completion = await client.chat.completions.create(
  File "/home/ubuntu/miniforge3/envs/orgsync/lib/python3.10/site-packages/openai/_utils/_utils.py", line 274, in wrapper
    return func(*args, **kwargs)
  File "/home/ubuntu/miniforge3/envs/orgsync/lib/python3.10/site-packages/openai/resources/chat/completions.py", line 742, in create
    return self._post(
  File "/home/ubuntu/miniforge3/envs/orgsync/lib/python3.10/site-packages/openai/_base_client.py", line 1277, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/ubuntu/miniforge3/envs/orgsync/lib/python3.10/site-packages/openai/_base_client.py", line 954, in request
    return self._request(
  File "/home/ubuntu/miniforge3/envs/orgsync/lib/python3.10/site-packages/openai/_base_client.py", line 990, in _request
    response = self._client.send(
  File "/home/ubuntu/miniforge3/envs/orgsync/lib/python3.10/site-packages/httpx/_client.py", line 926, in send
    response = self._send_handling_auth(
  File "/home/ubuntu/miniforge3/envs/orgsync/lib/python3.10/site-packages/httpx/_client.py", line 954, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/ubuntu/miniforge3/envs/orgsync/lib/python3.10/site-packages/httpx/_client.py", line 991, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/ubuntu/miniforge3/envs/orgsync/lib/python3.10/site-packages/httpx/_client.py", line 1027, in _send_single_request
    response = transport.handle_request(request)
  File "/home/ubuntu/miniforge3/envs/orgsync/lib/python3.10/site-packages/httpx/_transports/default.py", line 236, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/ubuntu/miniforge3/envs/orgsync/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/ubuntu/miniforge3/envs/orgsync/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/home/ubuntu/miniforge3/envs/orgsync/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 101, in handle_request
    return self._connection.handle_request(request)
  File "/home/ubuntu/miniforge3/envs/orgsync/lib/python3.10/site-packages/httpcore/_sync/http11.py", line 143, in handle_request
    raise exc
  File "/home/ubuntu/miniforge3/envs/orgsync/lib/python3.10/site-packages/httpcore/_sync/http11.py", line 113, in handle_request
    ) = self._receive_response_headers(**kwargs)
  File "/home/ubuntu/miniforge3/envs/orgsync/lib/python3.10/site-packages/httpcore/_sync/http11.py", line 186, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
  File "/home/ubuntu/miniforge3/envs/orgsync/lib/python3.10/site-packages/httpcore/_sync/http11.py", line 224, in _receive_event
    data = self._network_stream.read(
  File "/home/ubuntu/miniforge3/envs/orgsync/lib/python3.10/site-packages/httpcore/_backends/sync.py", line 126, in read
    return self._sock.recv(max_bytes)
  File "/home/ubuntu/miniforge3/envs/orgsync/lib/python3.10/ssl.py", line 1292, in recv
    return self.read(buflen)
  File "/home/ubuntu/miniforge3/envs/orgsync/lib/python3.10/ssl.py", line 1165, in read
    return self._sslobj.read(len)
KeyboardInterrupt
2025-02-20 15:53:53,104 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-5' coro=<process_group_with_llm() done, defined at /home/ubuntu/OrgSync/src/api_llm/gpt-4o/stages/stage6.py:96> exception=TypeError("object ChatCompletion can't be used in 'await' expression")>
Traceback (most recent call last):
  File "/home/ubuntu/OrgSync/src/api_llm/gpt-4o/stages/stage6.py", line 154, in process_group_with_llm
    completion = await client.chat.completions.create(
TypeError: object ChatCompletion can't be used in 'await' expression
2025-02-20 15:53:53,104 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-4' coro=<process_group_with_llm() done, defined at /home/ubuntu/OrgSync/src/api_llm/gpt-4o/stages/stage6.py:96> exception=TypeError("object ChatCompletion can't be used in 'await' expression")>
Traceback (most recent call last):
  File "/home/ubuntu/OrgSync/src/api_llm/gpt-4o/stages/stage6.py", line 154, in process_group_with_llm
    completion = await client.chat.completions.create(
TypeError: object ChatCompletion can't be used in 'await' expression
2025-02-20 15:53:53,104 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-3' coro=<process_group_with_llm() done, defined at /home/ubuntu/OrgSync/src/api_llm/gpt-4o/stages/stage6.py:96> exception=TypeError("object ChatCompletion can't be used in 'await' expression")>
Traceback (most recent call last):
  File "/home/ubuntu/OrgSync/src/api_llm/gpt-4o/stages/stage6.py", line 154, in process_group_with_llm
    completion = await client.chat.completions.create(
TypeError: object ChatCompletion can't be used in 'await' expression
2025-02-20 15:53:53,105 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-2' coro=<process_group_with_llm() done, defined at /home/ubuntu/OrgSync/src/api_llm/gpt-4o/stages/stage6.py:96> exception=TypeError("object ChatCompletion can't be used in 'await' expression")>
Traceback (most recent call last):
  File "/home/ubuntu/OrgSync/src/api_llm/gpt-4o/stages/stage6.py", line 154, in process_group_with_llm
    completion = await client.chat.completions.create(
TypeError: object ChatCompletion can't be used in 'await' expression
