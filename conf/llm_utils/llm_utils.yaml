# llm_utils.yaml (Base config)

models_dir: /home/ubuntu/OrgSync/llama-models/models
core_data_file: data/raw/from_tom/gtr/scraped/2024_07/organisations.json
project_root: /home/ubuntu/OrgSync
default_ckpt_dir: /home/ubuntu/OrgSync/.llama/checkpoints/Meta-Llama3.1-8B-Instruct
tokenizer_subpath: llama3/api/tokenizer.model

llm:
  max_seq_len: 8192
  max_batch_size: 4
  model_parallel_size: null

search:
  default_method: "duckduckgo"
  num_results: 3
  max_retries: 5
  pause_after_n_searches: 20
  pause_duration: 60

openai:
  api_key: ${env:OPENAI_API_KEY}








